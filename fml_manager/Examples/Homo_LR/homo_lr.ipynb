{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homo LR Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo, we use the homo_logistic_regression(https://github.com/FederatedAI/FATE/tree/master/examples/federatedml-1.x-examples/homo_logistic_regression example. It is:\n",
    "* Homogeneous federated machine learning example, which both parties share same attributes but different samples;\n",
    "* Use breast cancer data original from Kaggle: https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n",
    "* For easy to demo, both party we use the same FATE cluster: 10000. But the underlayer is the same, each side threat the collborated party go through the network to another party. \n",
    "\n",
    "Step 0. Prepare the libary to manage federated machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "\n",
    "import fml_manager\n",
    "\n",
    "manager = fml_manager.FMLManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1. Upload the guest, host and test data. Because we use same cluster for this demo, we load all data in same NOTEBOOK. If we use another party for host, the host data should load in the NOTEBOOK of that party."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'board_url': 'http://fateboard:8080/index.html#/dashboard?job_id=2020063006322784993833&role=local&party_id=0', 'job_dsl_path': '/data/projects/fate/python/jobs/2020063006322784993833/job_dsl.json', 'job_runtime_conf_path': '/data/projects/fate/python/jobs/2020063006322784993833/job_runtime_conf.json', 'logs_directory': '/data/projects/fate/python/logs/2020063006322784993833', 'namespace': 'homo_breast_guest', 'table_name': 'homo_breast_guest'}, 'jobId': '2020063006322784993833', 'retcode': 0, 'retmsg': 'success'}\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: success\n",
      "Status: success\n",
      "Status: success\n",
      "success,success,success\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "response = manager.load_data(url='./data/breast_homo_guest.csv', namespace='homo_breast_guest', table_name='homo_breast_guest', work_mode=1, head=1, partition=10)\n",
    "output = json.loads(response.content)\n",
    "print(output)\n",
    "guest_job_id = output[\"jobId\"]\n",
    "guest_query_condition = {\n",
    "    'job_id':guest_job_id\n",
    "}\n",
    "response = manager.load_data(url='./data/breast_homo_host.csv', namespace='homo_breast_host', table_name='homo_breast_host', work_mode=1, head=1, partition=10)\n",
    "output = json.loads(response.content)\n",
    "host_job_id = output[\"jobId\"]\n",
    "host_query_condition = {\n",
    "    'job_id':host_job_id\n",
    "}\n",
    "response = manager.load_data(url='./data/breast_homo_test.csv', namespace='homo_breast_test', table_name='homo_breast_test', work_mode=1, head=1, partition=10)\n",
    "output = json.loads(response.content)\n",
    "test_job_id = output[\"jobId\"]\n",
    "test_query_condition = {\n",
    "    'job_id':test_job_id\n",
    "}\n",
    "\n",
    "\n",
    "manager.query_job_status(guest_query_condition)\n",
    "manager.query_job_status(host_query_condition)\n",
    "manager.query_job_status(host_query_condition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. Create the steps DSL and configuration of each step for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsl = '''\n",
    "{\n",
    "    \"components\" : {\n",
    "        \"dataio_0\": {\n",
    "            \"module\": \"DataIO\",\n",
    "            \"input\": {\n",
    "                \"data\": {\n",
    "                    \"data\": [\n",
    "                        \"args.train_data\"\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"output\": {\n",
    "                \"data\": [\"train\"],\n",
    "                \"model\": [\"dataio\"]\n",
    "            }\n",
    "         },\n",
    "        \"homo_lr_0\": {\n",
    "            \"module\": \"HomoLR\",\n",
    "            \"input\": {\n",
    "                \"data\": {\n",
    "                    \"train_data\": [\n",
    "                        \"dataio_0.train\"\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"output\": {\n",
    "                \"data\": [\"train\"],\n",
    "                \"model\": [\"homolr\"]\n",
    "            }\n",
    "        },\n",
    "        \"evaluation_0\": {\n",
    "            \"module\": \"Evaluation\",\n",
    "            \"input\": {\n",
    "                \"data\": {\n",
    "                    \"data\": [\n",
    "                        \"homo_lr_0.train\"\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"output\": {\n",
    "                \"data\": [\"evaluate\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "'''\n",
    "\n",
    "config = '''\n",
    "{\n",
    "    \"initiator\": {\n",
    "        \"role\": \"guest\",\n",
    "        \"party_id\": 10000\n",
    "    },\n",
    "    \"job_parameters\": {\n",
    "        \"work_mode\": 1\n",
    "    },\n",
    "    \"role\": {\n",
    "        \"guest\": [10000],\n",
    "        \"host\": [10000],\n",
    "        \"arbiter\": [10000]\n",
    "    },\n",
    "    \"role_parameters\": {\n",
    "        \"guest\": {\n",
    "            \"args\": {\n",
    "                \"data\": {\n",
    "                    \"train_data\": [{\"name\": \"homo_breast_guest\", \"namespace\": \"homo_breast_guest\"}]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"host\": {\n",
    "            \"args\": {\n",
    "                \"data\": {\n",
    "                    \"train_data\": [{\"name\": \"homo_breast_host\", \"namespace\": \"homo_breast_host\"}]\n",
    "                }\n",
    "            },\n",
    "            \"evaluation_0\": {\n",
    "                \"need_run\": [false]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"algorithm_parameters\": {\n",
    "        \"dataio_0\":{\n",
    "            \"with_label\": true,\n",
    "            \"label_name\": \"y\",\n",
    "            \"label_type\": \"int\",\n",
    "            \"output_format\": \"dense\"\n",
    "        },\n",
    "        \"homo_lr_0\": {\n",
    "            \"penalty\": \"L2\",\n",
    "            \"optimizer\": \"sgd\",\n",
    "            \"eps\": 1e-5,\n",
    "            \"alpha\": 0.01,\n",
    "            \"max_iter\": 10,\n",
    "            \"converge_func\": \"diff\",\n",
    "            \"batch_size\": 500,\n",
    "            \"learning_rate\": 0.15,\n",
    "            \"decay\": 1,\n",
    "            \"decay_sqrt\": true,\n",
    "            \"init_param\": {\n",
    "                \"init_method\": \"zeros\"\n",
    "            },\n",
    "            \"encrypt_param\": {\n",
    "                \"method\": \"Paillier\"\n",
    "            },\n",
    "            \"cv_param\": {\n",
    "                \"n_splits\": 4,\n",
    "                \"shuffle\": true,\n",
    "                \"random_seed\": 33,\n",
    "                \"need_cv\": false\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3. Submit the training job to GUEST cluster. And it will notify and bring up the HOST cluster and train together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "{\n",
      "    \"data\": {\n",
      "        \"board_url\": \"http://fateboard:8080/index.html#/dashboard?job_id=2020063006362564981036&role=guest&party_id=9999\",\n",
      "        \"job_dsl_path\": \"/data/projects/fate/python/jobs/2020063006362564981036/job_dsl.json\",\n",
      "        \"job_runtime_conf_path\": \"/data/projects/fate/python/jobs/2020063006362564981036/job_runtime_conf.json\",\n",
      "        \"logs_directory\": \"/data/projects/fate/python/logs/2020063006362564981036\",\n",
      "        \"model_info\": {\n",
      "            \"model_id\": \"arbiter-9999#guest-9999#host-9999#model\",\n",
      "            \"model_version\": \"2020063006362564981036\"\n",
      "        }\n",
      "    },\n",
      "    \"jobId\": \"2020063006362564981036\",\n",
      "    \"retcode\": 0,\n",
      "    \"retmsg\": \"success\"\n",
      "}\n",
      "Status: waiting\n",
      "Status: waiting\n",
      "Status: waiting\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: success\n",
      "Success\n",
      "Success!\n",
      "{\n",
      "    \"data\": {\n",
      "        \"board_url\": \"http://fateboard:8080/index.html#/dashboard?job_id=2020063006362564981036&role=guest&party_id=9999\",\n",
      "        \"job_dsl_path\": \"/data/projects/fate/python/jobs/2020063006362564981036/job_dsl.json\",\n",
      "        \"job_runtime_conf_path\": \"/data/projects/fate/python/jobs/2020063006362564981036/job_runtime_conf.json\",\n",
      "        \"logs_directory\": \"/data/projects/fate/python/logs/2020063006362564981036\",\n",
      "        \"model_info\": {\n",
      "            \"model_id\": \"arbiter-9999#guest-9999#host-9999#model\",\n",
      "            \"model_version\": \"2020063006362564981036\"\n",
      "        }\n",
      "    },\n",
      "    \"jobId\": \"2020063006362564981036\",\n",
      "    \"retcode\": 0,\n",
      "    \"retmsg\": \"success\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = manager.submit_job(json.loads(dsl),json.loads(config))\n",
    "manager.prettify(response, verbose=True)\n",
    "stdout = json.loads(response.content)\n",
    "jobId = stdout[\"jobId\"]\n",
    "query_condition = {\n",
    "    'job_id':jobId\n",
    "}\n",
    "\n",
    "model_id, model_version = '', ''\n",
    "manager.query_job_status(query_condition)\n",
    "\n",
    "manager.prettify(response, verbose=True)\n",
    "output = json.loads(response.content)\n",
    "model_id, model_version = output[\"data\"][\"model_info\"][\"model_id\"], output[\"data\"][\"model_info\"][\"model_version\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': 'CgJMMhHxaOOItfjkPhl7FK5H4XqEPyIDc2dkMPQDOTMzMzMzM8M/QApKBGRpZmZQAlgB', 'parameters': 'CAoSUP4QBQQ+79o/Y+ScSvKa1j+RTreM/XfUPyk/T2KsNtM/ik0jT2po0j+lMOUXo9zRPwWjqz1MetE/3VWUfhkz0T8KB2etSv7QP5ymdO1A1tA/Ig0KAngwEbJDSoWA/sG/Ig0KAngxEcob/dudLr6/Ig0KAngyEWYZ+hcRpMG/Ig0KAngzEfWv/7Rc+r+/Ig0KAng0EbDD/W9RW7m/Ig0KAng1Eb6OMlppJri/Ig0KAng2EbIEbULVqru/Ig0KAng3ERQQVXbn+MG/Ig0KAng4EW6/Nt4yu7W/Ig0KAng5EQJZbnGtrKW/Ig4KA3gxMBEsGFvBSI3AvyIOCgN4MTERZZM+KKAGur8iDgoDeDEyEdGPglYzgMC/Ig4KA3gxMxHa0QRjolK+vyIOCgN4MTQR9tqVWW+Fr78iDgoDeDE1ETwimmbYbLO/Ig4KA3gyMBG7wwtUoXG0vyIOCgN4MTYRIGmQvHuRur8iDgoDeDIxEdqP/oYJfnY/Ig4KA3gxNxFSVtQreM/AvyIOCgN4MjIRzQmY7no3sr8iDgoDeDIzEcwFGjerVbK/Ig4KA3gxOBHDXhlmJQ2rvyIOCgN4MjQRoPtqyzc7iD8iDgoDeDE5EXOSYAuFHaM/Ig4KA3gyNRGNsnK5wSqBvyIOCgN4MjYRna/Rsrf0Gj8iDgoDeDI3EUcfkMZaT6a/Ig4KA3gyOBHXUPahnWidPyIOCgN4MjkRXdrDc3/ooD8pCAy8iYha4T8yAngwMgJ4MTICeDIyAngzMgJ4NDICeDUyAng2MgJ4NzICeDgyAng5MgN4MTAyA3gxMTIDeDEyMgN4MTMyA3gxNDIDeDE1MgN4MTYyA3gxNzIDeDE4MgN4MTkyA3gyMDIDeDIxMgN4MjIyA3gyMzIDeDI0MgN4MjUyA3gyNjIDeDI3MgN4MjgyA3gyOQ=='}\n"
     ]
    }
   ],
   "source": [
    "response = manager.model_output('guest', '10000', model_id, model_version, 'homo_lr_0.homolr:HomoLogisticRegression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can try offline prediction feature. Prediction also need both parts participant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data\":{\"board_url\":\"http://fateboard:8080/index.html#/dashboard?job_id=202005070653465729886&role=guest&party_id=10000\",\"job_dsl_path\":\"/data/projects/fate/python/jobs/202005070653465729886/job_dsl.json\",\"job_runtime_conf_path\":\"/data/projects/fate/python/jobs/202005070653465729886/job_runtime_conf.json\",\"logs_directory\":\"/data/projects/fate/python/logs/202005070653465729886\",\"model_info\":{\"model_id\":\"arbiter-10000#guest-10000#host-10000#model\",\"model_version\":\"202005070651022620445\"}},\"jobId\":\"202005070653465729886\",\"retcode\":0,\"retmsg\":\"success\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "is_vertical = False\n",
    "initiator_party_role = 'guest'\n",
    "initiator_party_id = '10000'\n",
    "work_mode = 1\n",
    "federated_roles = {\n",
    "        'guest': [10000],\n",
    "        'host': [10000],\n",
    "        'arbiter': [10000]\n",
    "}\n",
    "guest_data_name = 'homo_breast_test'\n",
    "guest_data_namespace = 'homo_breast_test'\n",
    "host_data_name = 'homo_breast_test'\n",
    "host_data_namespace = 'homo_breast_test'\n",
    "\n",
    "response = manager.offline_predict_on_dataset(is_vertical, initiator_party_role, initiator_party_id, work_mode, model_id, model_version, federated_roles, guest_data_name, guest_data_namespace, host_data_name, host_data_namespace)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result can be checked in FATE-Board."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
